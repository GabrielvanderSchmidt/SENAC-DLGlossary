# Estrutura da Rede


#### Perceptron (Neurônio Artificial)
É o tipo mais simples de rede neural **feedforward**, e hoje é usado como sinônimo para **neurônio artificial**, que é o bloco fundamental de **redes neurais artificiais**. Neurônios artificiais são agrupados lateralmente em **camadas densas**, e estas são empilhadas verticalmente para formar **redes neurais multicamadas**. Consiste de uma soma das entradas ponderadas pelos **pesos/parâmetros** conectados $$u = w_0 \cdot X_0 + … + w_n \cdot X_n + b$$ seguida de uma **função de ativação** não-linear $$g(u)$$. Um neurônio artificial é equivalente a uma regressão logística quando usando **função de ativação sigmóide**.

#### Perceptron Multicamadas (MLP) / Rede Neural Artificial
É um modelo formado pelo agrupamento de **camadas** de **neurônios artificiais**. O **aprendizado** ocorre através do ajuste dos seus **parâmetros** $$\Theta$$ (pesos $$w$$ e biases $$b$$), otimizados via **descida de gradiente estocástica** (SGD) e **backpropagation** (retropropagação dos erros) conforme uma **função de perda/custo** (loss/cost function, $$\mathcal{L}(\hat{y}, y)$$) a ser minimizada ou, em casos raros, uma **função objetivo/de utilidade** (objective/utility function) a ser maximisada.

#### Função de Ativação
Proporciona a não-linearidade que **camadas neurais** precisam para poderem **aprender** efetivamente, as quais caso contrário colapsariam em uma combinação linear equivalente a uma única camada. Algumas funções comuns usadas como ativação são:
- **Sigmóide/Logística**: Fórmula: $$\sigma (x) = \frac{1}{1 + e^{-x}}$$. Intervalo da função: $$(0, 1)$$. Intervalo da derivada: $$(0, 0.25]$$. Muito presente no começo de **perceptrons multicamadas**, especialmente por sua saída poder ser interpretada como uma probabilidade (útil em problemas de classificação). Caiu em desuso em favor da **tangente hiperbólica** e depois pela **ReLU** por exacerbar o problema de **vanishing gradients**. Ainda utilizada em aplicações específicas, como problemas de classificação com rótulos/labels não exclusivos (ex.: classificação multilabel).
- **Tangente hiperbólica**: Fórmula: $$tanh (x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$$. Intervalo da função: $$(-1, 1)$$. Intervalo da derivada: $$(0, 1]$$. Substituiu a função **sigmóide** como função de ativação padrão em redes neurais por ter várias características desejáveis, como **gradiente** mais íngreme (**convergência** mais rápida), saída centrada em zero (útil antes da adoção de **batch normalization**), e mitigação de **vanishing gradients** (quando $$x$$ próximo a zero/longe das "caudas" da tanh). Embora hoje muito menos comum que a **ReLU**, ainda aparece em certas arquiteturas e problemas específicos, como **redes neurais recursivas** (RNNs).
- **Rectified Linear Unit - ReLU**: Fórmula: $$ReLU (x) = max(0, x)$$. Intervalo da função: $$[0, \infty)$$. Intervalo da derivada: $$[0, 1]$$. Essa função e suas variações se tornaram a função de ativação padrão usada na maioria das redes neurais modernas por mitigarem **vanishing gradients** melhor do que a **tanh**. Isso ocorre porque a tanh tem **regiões de saturação** onde os valores de entrada ($$x$$) são comprimidos para o intervalo $$(-1, 1)$$, causando regiões planas na função (as “caudas” da tanh) onde o **gradiente** é muito próximo de zero (ou seja, vanishing gradients). A ReLU, por sua vez, tem apenas regiões onde o gradiente é exatamente 0 ou 1. Isso faz com a ReLU assuma um papel de **gating** no gradiente, permitindo ($$x > 0$$) ou não ($$x \le 0$$) o fluxo do gradiente para camadas anteriores. Isso, porém, implica na possibilidade de **dying ReLUs**, onde, para todos os **batches** do **conjunto de treino**, a entrada $$x$$ da ReLU é menor que zero, impedindo a propagação do gradiente e consequentemente a "morte" daquele neurônio, pois seus pesos não serão atualizados. Embora aconteça, **técnicas de inicialização de pesos** (ex.: He), ou outras formas de **regularização** da rede fazem com que isso raramente seja um problema na prática. Possui várias variantes, como a **Leaky ReLU**, **[Scaled] Exponential Linear Unit**, **Randomized ReLU**, entre outras.

#### Camada Densa
É o tipo de camada neural mais simples encontrado dentro de uma **rede neural artificial**. É composta por vários **neurônios artificiais** que operam em conjunto, em um mesmo nível hierárquico dentro do fluxo de informação dentro da rede. É chamada de camada “densa” por todos os seus neurônios estarem conectados a todas as saídas da camada anterior, propriedade a qual pode levar ao aumento exponencial de **parâmetros** da rede se não observada durante a sua definição. Embora comumente apresentada como uma única unidade, englobando tanto a soma ponderada quanto a **função de ativação**, sua implementação em código frequentemente separa esta camada em uma transformação linear (ex.: `nn.Linear`) seguida de uma ativação (ex.: `nn.ReLU`).

#### Camada Convolucional
É uma camada que performa uma **convolução** entre um vetor/matriz de entrada e um conjunto de **filtros/kernels** (vetores/matrizes pequenos) cujos coeficientes são **parâmetros** aprendidos, ajustados durante o treinamento da rede (ao invés dos coeficientes fixos usados em convolução tradicional). Devido ao funcionamento da convolução, cada filtro aprendido produz um novo sinal em sua saída - um **mapa de características** (feature/activation map) - o que difere de **camadas densas**, onde cada **neurônio** produz uma única saída. Por conta disso, camadas convolucionais precisam saber apenas do número de canais de entrada, e não das dimensões de cada canal. Camadas convolucionais possuem vários **hiperparâmetros** importantes, como **número de filtros** aprendidos, **tamanho dos kernels** (tipicamente $$(3 \times 3)$$, $$(5 \times 5)$$, ou $$(7 \times 7)$$ em **CNNs**), **stride** (que implica numa redução de dimensões quando $$stride > 1$$ de forma análoga a **Max/Average Pooling**), **padding** (que pode causar pequenas diferenças entre as dimensões dos feature maps de entrada e de saída), entre outros.


# Termos e Conceitos


#### Aprendizado
No contexto de **machine learning**, significa melhorar o desempenho de um algoritmo (modelo) com base em experiência. "Experiência" se manifesta na forma de **dados** para treinamento. "Desempenho" é medido em termos de **métricas** que definem o objetivo do sistema (ex.: **Mean Squared Error** - MSE). A "melhora" ocorre através do ajuste de **parâmetros** segundo um **algoritmo de otimização** (ex.: **Stochastic Gradient Descent** - SGD).

#### Descida de Gradiente Estocástica (SGD)
Algoritmo basilar do aprendizado de **redes neurais artificiais**. É um algoritmo iterativo que ajusta os **parâmetros** de um modelo na direção oposta ao seu **gradiente**, minimizando sua **loss function**. Essa descida de gradiente é estocástica pois opera em **estimativas** do gradiente global (o gradiente calculado sobre o **dataset** inteiro) obtidas a partir do gradiente calculado em **batches** (amostras) dos dados.
